@article{Andrews1974,
  abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.. Wiley-Blackwell and Royal Statistical Society are collaborating with JSTOR to digitize, preserve and extend access to Journal of the Royal Statistical Society. Series B (Methodological). SUMMARY This paper presents necessary and sufficient conditions under which a random variable X may be generated as the ratio ZI V where Z and V are independent and Z has a standard normal distribution. This representation is useful in Monte Carlo calculations. It is established that when 7 V2 is exponential, X is double exponential; and that when WV has the asymptotic distribution of the Kolmogorov distance statistic, X is logistic.},
  author = {Andrews, D. F. and Mallows, C. L.},
  doi = {10.1111/j.2517-6161.1974.tb00989.x},
  file = {:Users/wglaive/Desktop/scale mixture of normal.pdf:pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  mendeley-groups = {Horseshoe},
  month = {sep},
  number = {1},
  pages = {99--102},
  publisher = {Wiley},
  title = {{Scale Mixtures of Normal Distributions}},
  volume = {36},
  year = {1974}
}
@article{West1987,
  abstract = {The exponential power family of distributions of Box {\&} Tiao (1973) is shown to be a subset of the class of scale mixtures of normals. The corresponding mixing distributions are explicitly obtained, identifying a close relationship between the exponential power family and a further class of normal scale mixtures, namely the stable distributions. {\textcopyright} 1987 Biometrika Trust.},
  author = {West, Mike},
  doi = {10.1093/biomet/74.3.646},
  file = {:Users/wglaive/Library/Application Support/Mendeley Desktop/Downloaded/West - 1987 - On scale mixtures of normal distributions.pdf:pdf},
  issn = {00063444},
  journal = {Biometrika},
  keywords = {Exponential power family,Scale mixture of normals,Stable distribution},
  mendeley-groups = {Horseshoe},
  number = {3},
  pages = {646--648},
  title = {{On scale mixtures of normal distributions}},
  url = {https://academic.oup.com/biomet/article/74/3/646/238820},
  volume = {74},
  year = {1987}
}
@article{Bhattacharya2016,
  abstract = {We propose an efficient way to sample from a class of structured multivariate Gaussian distributions. The proposed algorithm only requires matrix multiplications and linear system solutions. Its computational complexity grows linearly with the dimension, unlike existing algorithms that rely on Cholesky factorizations with cubic complexity. The algorithm is broadly applicable in settings where Gaussian scale mixture priors are used on high-dimensional parameters. Its effectiveness is illustrated through a high-dimensional regression problem with a horseshoe prior on the regression coefficients. Other potential applications are outlined.},
  author = {Bhattacharya, Anirban and Chakraborty, Antik and Mallick, Bani K.},
  doi = {10.1093/biomet/asw042},
  file = {:Users/wglaive/Desktop/asw042.pdf:pdf},
  issn = {14643510},
  journal = {Biometrika},
  keywords = {Confidence interval,Gaussian scale mixture,Global-local prior,Shrinkage,Sparsity.},
  mendeley-groups = {Horseshoe},
  month = {dec},
  number = {4},
  pages = {985--991},
  publisher = {Oxford University Press},
  title = {{Miscellanea fast sampling with Gaussian scale mixture priors in high-dimensional regression}},
  url = {https://academic.oup.com/biomet/article/103/4/985/2447851},
  volume = {103},
  year = {2016}
}
@article{Polson2014,
  abstract = {We propose the Bayesian bridge estimator for regularized regression and classification. Two key mixture representations for the Bayesian bridge model are developed: a scale mixture of normal distributions with respect to an $\alpha$-stable random variable; a mixture of Bartlett-Fejer kernels (or triangle densities) with respect to a two-component mixture of gamma random variables. Both lead to Markov chain Monte Carlo methods for posterior simulation, and these methods turn out to have complementary domains of maximum efficiency. The first representation is a well-known result due to West and is the better choice for collinear design matrices. The second representation is new and is more efficient for orthogonal problems, largely because it avoids the need to deal with exponentially tilted stable random variables. It also provides insight into the multimodality of the joint posterior distribution, which is a feature of the bridge model that is notably absent under ridge or lasso-type priors. We prove a theorem that extends this representation to a wider class of densities representable as scale mixtures of beta distributions, and we provide an explicit inversion formula for the mixing distribution. The connections with slice sampling and scale mixtures of normal distributions are explored. On the practical side, we find that the Bayesian bridge model outperforms its classical cousin in estimation and prediction across a variety of data sets, both simulated and real. We also show that the Markov chain Monte Carlo algorithm for fitting the bridge model exhibits excellent mixing properties, particularly for the global scale parameter. This makes for a favourable contrast with analogous Markov chain Monte Carlo algorithms for other sparse Bayesian models. All methods described in this paper are implemented in the R package BayesBridge. An extensive set of simulation results is provided in two on-line supplemental files. {\textcopyright} 2013 Royal Statistical Society.},
  archivePrefix = {arXiv},
  arxivId = {1109.2279},
  author = {Polson, Nicholas G. and Scott, James G. and Windle, Jesse},
  doi = {10.1111/rssb.12042},
  eprint = {1109.2279},
  file = {:Users/wglaive/Downloads/rssb.12042.pdf:pdf},
  issn = {14679868},
  journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  keywords = {Bayesian methods,Bridge estimator,Data augmentation,Prior distributions,Sparsity},
  mendeley-groups = {Horseshoe},
  month = {sep},
  number = {4},
  pages = {713--733},
  publisher = {Blackwell Publishing Ltd},
  title = {{The Bayesian bridge}},
  url = {http://doi.wiley.com/10.1111/rssb.12042},
  volume = {76},
  year = {2014}
}
@inproceedings{Carvalho2009,
  abstract = {This paper presents a general, fully Bayesian framework for sparse supervised-learning problems based on the horseshoe prior. The horseshoe prior is a member of the family of multivariate scale mixtures of normals, and is therefore closely related to widely used approaches for sparse Bayesian learning, including, among others, Laplacian priors (e.g. the LASSO) and Student-t priors (e.g. the relevance vector machine). The advantages of the horseshoe are its robustness at handling unknown sparsity and large outlying signals. These properties are justified theoretically via a representation theorem and accompanied by comprehensive empirical experiments that compare its performance to benchmark alternatives. {\textcopyright} 2009 by the authors.},
  author = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
  booktitle = {Journal of Machine Learning Research},
  file = {:Users/wglaive/Library/Application Support/Mendeley Desktop/Downloaded/Carvalho, Polson, Scott - 2009 - Handling Sparsity via the Horseshoe.pdf:pdf},
  issn = {15324435},
  mendeley-groups = {Horseshoe},
  pages = {73--80},
  title = {{Handling sparsity via the horseshoe}},
  volume = {5},
  year = {2009}
}
@article{Carvalho2010,
  abstract = {This paper proposes a new approach to sparsity, called the horseshoe estimator, which arises from a prior based on multivariate-normal scale mixtures. We describe the estimator's advantages over existing approaches, including its robustness, adaptivity to different sparsity patterns and analytical tractability. We prove two theorems: one that characterizes the horseshoe estimator's tail robustness and the other that demonstrates a super-efficient rate of convergence to the correct estimate of the sampling density in sparse situations. Finally, using both real and simulated data, we show that the horseshoe estimator corresponds quite closely to the answers obtained by Bayesian model averaging under a point-mass mixture prior. {\textcopyright} 2010 Biometrika Trust.},
  author = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
  doi = {10.1093/biomet/asq017},
  file = {:Users/wglaive/Library/Application Support/Mendeley Desktop/Downloaded/Carvalho, Polson, Scott - 2010 - The horseshoe estimator for sparse signals.pdf:pdf},
  issn = {00063444},
  journal = {Biometrika},
  keywords = {Normal scale mixture,Ridge regression,Robustness,Shrinkage,Sparsity,Thresholding},
  mendeley-groups = {Horseshoe},
  number = {2},
  pages = {465--480},
  title = {{The horseshoe estimator for sparse signals}},
  url = {https://academic.oup.com/biomet/article/97/2/465/219397},
  volume = {97},
  year = {2010}
}
@article{Damien1999,
abstract = {We demonstrate the use of auxiliary (or latent) variables for sampling non-standard densities which arise in the context of the Bayesian analysis of non-conjugate and hierarchical models by using a Gibbs sampler. Their strategic use can result in a Gibbs sampler having easily sampled full conditionals. We propose such a procedure to simplify or speed up the Markov chain Monte Carlo algorithm. The strength of this approach lies in its generality and its ease of implementation. The aim of the paper, therefore, is to provide an alternative sampling algorithm to rejection-based methods and other sampling approaches such as the Metropolis-Hastings algorithm.},
author = {Damien, Paul and Wakefield, Jon and Walker, Stephen},
doi = {10.1111/1467-9868.00179},
file = {:Users/wglaive/Desktop/2680644.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Gibbs sampler,Hierarchical model,Latent variable,Non-conjugate model},
number = {2},
pages = {331--344},
publisher = {Blackwell Publishing Ltd},
title = {{Gibbs sampling for Bayesian non-conjugate and hierarchical models by using auxiliary variables}},
volume = {61},
year = {1999}
}
