<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.1.0">
  <meta name="generator" content="Hugo 0.54.0" />

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jiaming Shen">

  
  
  
    
  
  <meta name="description" content="使用Horseshoe 先验的Bayes回归及代码解析 Horseshoe prior是一种稀疏bayes监督学习的方法。通过对模型参数的先验分布中加入稀疏特征，从而得到稀疏的估计。
horseshoe prior属于multivariate scale mixtures of normals的分布族。所以和其他常用的稀疏bayes学习方法，Laplacian prior, (Lasso), Student-t prior，非常类似。
在回归问题下的模型假设： \[ y=X\beta&#43;\epsilon, \epsilon\sim N(0,\sigma^2)\\ \beta_j \sim N(0,\sigma^2 \lambda_j^2 \tau^2)\\ \lambda_j \sim Half-Cauchy(0,1) \] 可以额外加上以下超参数模型 \[ \tau \sim Half-Cauchy (0,1)\\ \sigma^2 \sim 1/\sigma^2 \]
其中\(\lambda_j\) 叫做local shrinkage parameter，局部压缩参数，对于不同的\(\theta_j\)可以有不同的压缩系数，\(\tau\) 叫做global shrinkage parameter
叫horseshoe，马蹄的原因大概是shrinkage weights的图像呈现马蹄形。
Carvalho, Polson, and Scott (2010) 给出了几个horseshoe estimator的相关性质以及和传统其他压缩先验方法的比较。
这篇文章给出了一个用于判断各种压缩先验性质的方法: \[ E\left(\theta_{i} \mid y\right)=\int_{0}^{1}\left(1-\kappa_{i}\right) y_{i} p\left(\kappa_{i} \mid y\right) \mathrm{d} \kappa_{i}=\left\{1-E\left(\kappa_{i} \mid y\right)\right\} y_{i} \] 在这种情况下, \(E(\kappa_i|y)\) 就是压缩率。">

  
  <link rel="alternate" hreflang="en-us" href="/post/horseshoe-bayes/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Academic">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Academic">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/horseshoe-bayes/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Academic">
  <meta property="og:url" content="/post/horseshoe-bayes/">
  <meta property="og:title" content="使用Horseshoe 先验的Bayes回归及代码解析 | Academic">
  <meta property="og:description" content="使用Horseshoe 先验的Bayes回归及代码解析 Horseshoe prior是一种稀疏bayes监督学习的方法。通过对模型参数的先验分布中加入稀疏特征，从而得到稀疏的估计。
horseshoe prior属于multivariate scale mixtures of normals的分布族。所以和其他常用的稀疏bayes学习方法，Laplacian prior, (Lasso), Student-t prior，非常类似。
在回归问题下的模型假设： \[ y=X\beta&#43;\epsilon, \epsilon\sim N(0,\sigma^2)\\ \beta_j \sim N(0,\sigma^2 \lambda_j^2 \tau^2)\\ \lambda_j \sim Half-Cauchy(0,1) \] 可以额外加上以下超参数模型 \[ \tau \sim Half-Cauchy (0,1)\\ \sigma^2 \sim 1/\sigma^2 \]
其中\(\lambda_j\) 叫做local shrinkage parameter，局部压缩参数，对于不同的\(\theta_j\)可以有不同的压缩系数，\(\tau\) 叫做global shrinkage parameter
叫horseshoe，马蹄的原因大概是shrinkage weights的图像呈现马蹄形。
Carvalho, Polson, and Scott (2010) 给出了几个horseshoe estimator的相关性质以及和传统其他压缩先验方法的比较。
这篇文章给出了一个用于判断各种压缩先验性质的方法: \[ E\left(\theta_{i} \mid y\right)=\int_{0}^{1}\left(1-\kappa_{i}\right) y_{i} p\left(\kappa_{i} \mid y\right) \mathrm{d} \kappa_{i}=\left\{1-E\left(\kappa_{i} \mid y\right)\right\} y_{i} \] 在这种情况下, \(E(\kappa_i|y)\) 就是压缩率。"><meta property="og:image" content="/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-09-21T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2020-09-21T00:00:00&#43;00:00">
  

  

  

  <title>使用Horseshoe 先验的Bayes回归及代码解析 | Academic</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Academic</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#featured">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/slides/">
            
            <span>Slides</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#Notes">
            
            <span>Notes</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">使用Horseshoe 先验的Bayes回归及代码解析</h1>

  

  
    



<meta content="2020-09-21 00:00:00 &#43;0000 UTC" itemprop="datePublished">
<meta content="2020-09-21 00:00:00 &#43;0000 UTC" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Sep 21, 2020</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/horseshoe-bayes/#disqus_thread"></a>
  

  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=%e4%bd%bf%e7%94%a8Horseshoe%20%e5%85%88%e9%aa%8c%e7%9a%84Bayes%e5%9b%9e%e5%bd%92%e5%8f%8a%e4%bb%a3%e7%a0%81%e8%a7%a3%e6%9e%90&amp;url=%2fpost%2fhorseshoe-bayes%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fhorseshoe-bayes%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fhorseshoe-bayes%2f&amp;title=%e4%bd%bf%e7%94%a8Horseshoe%20%e5%85%88%e9%aa%8c%e7%9a%84Bayes%e5%9b%9e%e5%bd%92%e5%8f%8a%e4%bb%a3%e7%a0%81%e8%a7%a3%e6%9e%90"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fhorseshoe-bayes%2f&amp;title=%e4%bd%bf%e7%94%a8Horseshoe%20%e5%85%88%e9%aa%8c%e7%9a%84Bayes%e5%9b%9e%e5%bd%92%e5%8f%8a%e4%bb%a3%e7%a0%81%e8%a7%a3%e6%9e%90"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=%e4%bd%bf%e7%94%a8Horseshoe%20%e5%85%88%e9%aa%8c%e7%9a%84Bayes%e5%9b%9e%e5%bd%92%e5%8f%8a%e4%bb%a3%e7%a0%81%e8%a7%a3%e6%9e%90&amp;body=%2fpost%2fhorseshoe-bayes%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    















  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="使用horseshoe-先验的bayes回归及代码解析" class="section level1">
<h1>使用Horseshoe 先验的Bayes回归及代码解析</h1>
<p>Horseshoe prior是一种稀疏bayes监督学习的方法。通过对模型参数的先验分布中加入稀疏特征，从而得到稀疏的估计。</p>
<p>horseshoe prior属于multivariate scale mixtures of normals的分布族。所以和其他常用的稀疏bayes学习方法，Laplacian prior, (Lasso), Student-t prior，非常类似。</p>
<p>在回归问题下的模型假设：
<span class="math display">\[
y=X\beta+\epsilon, \epsilon\sim N(0,\sigma^2)\\
\beta_j \sim N(0,\sigma^2 \lambda_j^2 \tau^2)\\
\lambda_j \sim Half-Cauchy(0,1)
\]</span>
可以额外加上以下超参数模型
<span class="math display">\[
\tau \sim Half-Cauchy (0,1)\\
\sigma^2 \sim 1/\sigma^2
\]</span></p>
<p>其中<span class="math inline">\(\lambda_j\)</span> 叫做local shrinkage parameter，局部压缩参数，对于不同的<span class="math inline">\(\theta_j\)</span>可以有不同的压缩系数，<span class="math inline">\(\tau\)</span> 叫做global shrinkage parameter</p>
<p>叫horseshoe，马蹄的原因大概是shrinkage weights的图像呈现马蹄形。</p>
<p><span class="citation">Carvalho, Polson, and Scott (2010)</span> 给出了几个horseshoe estimator的相关性质以及和传统其他压缩先验方法的比较。</p>
<p>这篇文章给出了一个用于判断各种压缩先验性质的方法:
<span class="math display">\[
E\left(\theta_{i} \mid y\right)=\int_{0}^{1}\left(1-\kappa_{i}\right) y_{i} p\left(\kappa_{i} \mid y\right) \mathrm{d} \kappa_{i}=\left\{1-E\left(\kappa_{i} \mid y\right)\right\} y_{i}
\]</span>
在这种情况下, <span class="math inline">\(E(\kappa_i|y)\)</span> 就是压缩率。</p>
<p>而horseshoe prior在这个指标下就相对很优秀：对于很小的参数，压缩效果明显，对于相对比较大的参数，几乎不压缩。</p>
<p><a href="https://cran.r-project.org/web/packages/horseshoe/index.html">R包horseshoe</a>提供了horseshoe estimator的计算函数，而本文主要目的就是对<a href="https://github.com/cran/horseshoe/blob/master/R/horseshoe.R">horseshoe.R</a>中的算法进行整合和解析。</p>
<pre class="r"><code>horseshoe = function(y,X, method.tau = c(&quot;fixed&quot;, &quot;truncatedCauchy&quot;,&quot;halfCauchy&quot;), tau = 1,
                     method.sigma = c(&quot;fixed&quot;, &quot;Jeffreys&quot;), Sigma2 = 1,
                     burn = 1000, nmc = 5000, thin = 1, alpha = 0.05)</code></pre>
<p>函数的定义，对于 <span class="math inline">\(\tau\)</span> 可以选择常数，截尾柯西分布和半柯西分布，默认的tau是1，同样 <span class="math inline">\(\sigma\)</span> 也可以选择固定值和Jeffreys prior (<span class="math inline">\(\sim 1/\sigma^2\)</span>) 。</p>
<pre class="r"><code>if(p&gt;n)
    algo=1
  else
    algo=2</code></pre>
<p>在函数介绍中就有，当p&gt;n时，使用的是 <span class="citation">Bhattacharya, Chakraborty, and Mallick (2016)</span> 的算法，当n&gt;p时，使用的是 Rue (2001)的算法对<span class="math inline">\(\beta\)</span> 的full conditional posterior distribution进行抽样。</p>
<p>因为是Normal-Normal case，conditional on <span class="math inline">\(\sigma,\tau,\lambda\)</span> ,<span class="math inline">\(\beta\)</span> 是Normal prior加Normal likelihood，所以对于Bayes回归问题，beta的全条件后验分布基本上可以写成:
<span class="math display">\[
\beta \mid y, \lambda, \tau, \sigma \sim N\left(A^{-1} X^{\mathrm{T}} y, \sigma^{2} A^{-1}\right), \quad A=\left(X^{\mathrm{T}} X+\Lambda_{*}^{-1}\right), \quad \Lambda_{*}=\tau^{2} \operatorname{diag}\left(\lambda_{1}^{2}, \ldots, \lambda_{p}^{2}\right)
\]</span>
这种形式，所以就是用Gibbs算法对<span class="math inline">\(\beta\)</span> 抽样。</p>
<p>现在介绍在p&gt;n情况下的算法。</p>
<p><a href="mailto:来源于@Bhattacharya2016" class="email">来源于@Bhattacharya2016</a> ，</p>
<p>假设我们要从<span class="math inline">\(N(\mu,\Sigma)\)</span>中抽样，有
<span class="math display">\[
\Sigma=\left(\Phi^{\mathrm{T}} \Phi+D^{-1}\right)^{-1}, \quad \mu=\Sigma \Phi^{\mathrm{T}} \alpha
\]</span>
算法如下</p>
<ol style="list-style-type: decimal">
<li>抽 <span class="math inline">\(u\sim N(0,D)\)</span> , <span class="math inline">\(\delta\sim N(0,I_n)\)</span></li>
<li>令 <span class="math inline">\(v=\Phi u+\delta\)</span></li>
<li>解线性方程<span class="math inline">\((\Phi D \Phi^T+I_n)w=(\alpha-v)\)</span> 得到w</li>
<li>令<span class="math inline">\(\theta=u+D\Phi^T w\)</span></li>
</ol>
<p>算法的推导过程是：</p>
<p>我们目标是从<span class="math inline">\(N(\mu,\Sigma)\)</span> 中进行抽样，由于
<span class="math display">\[
\Sigma=(\Phi^T\Phi+D^{-1})^{-1}=D-D\Phi(\Phi D\Phi^T+I_n^{-1})^{-1}\Phi D
\]</span>
那么第一块D，则可以通过抽<span class="math inline">\(u\sim N(0,D)\)</span> 直接得到，也就是算法第4步中的<span class="math inline">\(u\)</span>. 问题就是怎么得到第二块。</p>
<p>第二块等于
<span class="math display">\[
\begin{align*}
&amp;D\Phi(\Phi D\Phi^T+I_n^{-1})^{-1}\Phi D\\
=&amp;D\Phi^T(\Phi D\Phi^T+I_n)^{-1}(\Phi D \Phi ^T+I_n)(\Phi D\Phi^T+I_n)^{-1}\Phi D
\end{align*}
\]</span>
因为
<span class="math display">\[
\begin{align*}
\mu&amp;=\Sigma\Phi^T\alpha=(\Phi^T\Phi+D^{-1})^{-1}\Phi^T\alpha=(D\Phi^T-D\Phi^T(\Phi D\Phi^T+I_n)^{-1}\Phi D\Phi^T)\alpha\\
&amp;=D\Phi^T (\Phi D\Phi^T+I_n)^{-1}\alpha
\end{align*}
\]</span>
所以相当于只需要对<span class="math inline">\(N(0,(\Phi D\Phi^T+I_n))\)</span> 加上<span class="math inline">\(\alpha\)</span>再做线性变换 <span class="math inline">\(D\Phi^T\cdot (\Phi D\Phi^{T}+I_n)^{-1}\)</span> 就能得到第二块的分布，也就对应算法过程3和4。</p>
<p>而为了得到<span class="math inline">\(N(0,(\Phi D\Phi^T+I_n))\)</span>，则只需要对<span class="math inline">\(u\sim N(0,D)\)</span> 乘以<span class="math inline">\(\Phi\)</span> 加<span class="math inline">\(\delta \sim N(0,I_n)\)</span>， 对应算法过程2。</p>
<p>这样的算法过程就对应代码：</p>
<pre class="r"><code> lambda_star=tau*lambda
      U=as.numeric(lambda_star^2)*t(X)
      ## step 1 ##
      u=stats::rnorm(l2,l0,lambda_star)
      v=X%*%u + stats::rnorm(n)
      ## step 2 ##
      v_star=solve((X%*%U+I_n),((y/sqrt(sigma_sq))-v))
      Beta=sqrt(sigma_sq)*(u+U%*%v_star)</code></pre>
<p>当p&lt;n,也就是algo==2时则是用经典的Cholesky分解进行抽样，故不再赘述。</p>
<p>下一块则是抽取<span class="math inline">\(\lambda_j\)</span> 的过程，这块算法使用了 <span class="citation">Polson, Scott, and Windle (2014)</span> 的supplement material中，使用 <span class="citation">Damien, Wakefield, and Walker (1999)</span> 算法构造的Slice sampler。</p>
<p>首先，我们可以写出<span class="math inline">\(\lambda_j\)</span> 的后验分布：
<span class="math display">\[
p(\lambda_j|y,\tau,\sigma)\propto \frac{2}{\pi(1+\lambda_j^2)}\cdot \frac{1}{\lambda_j}\cdot exp(-\frac{1}{\lambda_j^2}\frac{\beta_j^2}{2\tau^2\sigma^2} )
\]</span>
做变量代换: <span class="math inline">\(\eta_j=1/\lambda_j^2\)</span>, <span class="math inline">\(\mu_j=\beta_j/(\tau\sigma)\)</span>. 那么<span class="math inline">\(\lambda_j\)</span> 的full-conditional distribution转变为<span class="math inline">\(\eta_j\)</span>的 full conditional distribution,由<a href="https://kmsmgsh.github.io/Notes-in-statistics-and-computing/mathematical-statistic-trick.html#section-2.2">变量代换公式</a>:
<span class="math display">\[
p(\eta_j|y,\tau,\sigma)\propto \frac{1}{\eta_j+1}\cdot exp(-\frac{\mu_j^2}{2}\eta_j)
\]</span>
然后通过Damien et. al. (1999)的Slice sampler:</p>
<p>如果要生成密度函数为<span class="math inline">\(f\)</span> 的随机数，<span class="math inline">\(f\)</span> 可以写成如下形式:
<span class="math display">\[
f(x) \propto \pi(x) \prod_{i=1}^{N} l_{i}(x)
\]</span>
其中<span class="math inline">\(\pi(x)\)</span> 是已知形式的密度函数，<span class="math inline">\(l_i\)</span> 是非负可逆函数，也就是如果有 <span class="math inline">\(l_i(x)&gt;u\)</span>，那么可以反推出<span class="math inline">\(A^i_u=\{x:l_i(x)&gt;u \}\)</span>。那么就可以通过添加辅助变量的方法生成服从<span class="math inline">\(f\)</span> 的随机数。</p>
<p>令辅助变量 <span class="math inline">\(u_i|x \sim unif (0,l_i(x))\)</span>, 那么<span class="math inline">\(U\)</span> 和<span class="math inline">\(x\)</span> 的联合分布就是
<span class="math display">\[
f\left(x, u_{1}, \ldots, u_{N}\right) \propto \pi(x) \prod_{i=1}^{N} I\left\{u_{i}&lt;l_{i}(x)\right\}
\]</span>
这样，关于X的边际分布就是<span class="math inline">\(f(x)\)</span>。我们构造Gibbs sampler，其中<span class="math inline">\(u_i\)</span> 的full conditional distribution就是够早的uniform, 而X的full conditional distribution，则是分布<span class="math inline">\(\pi\)</span>, 但是局限在区域<span class="math inline">\(A_{u}=\left\{x: l_{i}(x)&gt;u_{i}, i=1, \ldots, N\right\}\)</span>.</p>
<p>因为<span class="math inline">\(\pi\)</span>是已知好抽的分布，<span class="math inline">\(l_i\)</span>是可逆函数，所以就把问题变成求区域和从好抽的分布中抽的问题。</p>
<p>应用在如上例子中，就是 <span class="math inline">\(l(\eta_j)=\frac{1}{\eta_j+1}\)</span> , <span class="math inline">\(\pi(\eta_j)=exp(-\frac{\mu_j^2}{2}\eta_j)\)</span> 是指数分布。</p>
<p>那算法：</p>
<ol style="list-style-type: decimal">
<li><p>从<span class="math inline">\((0,l(\eta_j))\)</span>中抽<span class="math inline">\(u\)</span> .</p></li>
<li><p>求区域 <span class="math inline">\(A_u = \{\eta_j,l(\eta_j)&gt;u\}\)</span>, 也就是<span class="math inline">\((0,\frac{1}{u}-1)\)</span></p></li>
<li><p>在限制于<span class="math inline">\((0,\frac{1}{u}-1)\)</span> 的exp分布上抽<span class="math inline">\(\eta_j\)</span>。</p></li>
</ol>
<p>这样就能得到<span class="math inline">\(\eta_j\)</span>。然后再逆变化回<span class="math inline">\(\lambda_j\)</span> 就能得到<span class="math inline">\(\lambda_j\)</span> 的样本，又因为<span class="math inline">\(\lambda_j\)</span>之间是独立的，所以这一步能向量化操作同时对所有的p个<span class="math inline">\(\lambda_j\)</span>抽样。</p>
<p>其中第三步的算法实现是：</p>
<p>由于局限在了<span class="math inline">\((0,\frac{1}{u}-1)\)</span> 上，而指数分布是单调的。就可以用一般的分布抽样的方法，从定义在<span class="math inline">\((0, F(\frac{1}{u}-1))\)</span>的uniform抽，F是累积分布函数, 在这里就是 <span class="math inline">\(1-exp(-\mu_j\cdot (\frac{1}{u}-1))\)</span>, 然后再逆回去，得到目标随机数。</p>
<p>算法：</p>
<ol style="list-style-type: decimal">
<li>从<span class="math inline">\((0,1-exp(-\mu_j\cdot (\frac{1}{u}-1)))\)</span> 中抽 <span class="math inline">\(a\)</span></li>
<li><span class="math inline">\(\eta_j= -log(1-a)/\mu_j\)</span></li>
</ol>
<p>对应代码：</p>
<pre class="r"><code>## update lambda_j&#39;s in a block using slice sampling ##
    eta = 1/(lambda^2)
    upsi = stats::runif(p,0,1/(1+eta))
    tempps = Beta^2/(2*sigma_sq*tau^2)
    ub = (1-upsi)/upsi
    # now sample eta from exp(tempv) truncated between 0 &amp; upsi/(1-upsi)
    Fub = 1 - exp(-tempps*ub) # exp cdf at ub
    Fub[Fub &lt; (1e-4)] = 1e-4;  # for numerical stability
    up = stats::runif(p,0,Fub)
    eta = -log(1-up)/tempps
    lambda = 1/sqrt(eta);</code></pre>
<p>剩下的更新<span class="math inline">\(\tau\)</span> 的部分类似。但是由于<span class="math inline">\(\tau\)</span>是全局的参数，所以单个式子的形式就变成了叠乘的形式，所以就从exp分布变味了gamma分布。</p>
<p>The density of <span class="math inline">\(\tau\)</span></p>
<p>Gamma distribution <span class="math inline">\(f(x)=\frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}\)</span></p>
<div id="refs" class="references hanging-indent">
<div id="ref-Bhattacharya2016">
<p>Bhattacharya, Anirban, Antik Chakraborty, and Bani K. Mallick. 2016. “Miscellanea fast sampling with Gaussian scale mixture priors in high-dimensional regression.” <em>Biometrika</em> 103 (4): 985–91. <a href="https://doi.org/10.1093/biomet/asw042">https://doi.org/10.1093/biomet/asw042</a>.</p>
</div>
<div id="ref-Carvalho2010">
<p>Carvalho, Carlos M, Nicholas G Polson, and James G Scott. 2010. “The horseshoe estimator for sparse signals.” <em>Biometrika</em> 97 (2): 465–80. <a href="https://doi.org/10.1093/biomet/asq017">https://doi.org/10.1093/biomet/asq017</a>.</p>
</div>
<div id="ref-Damien1999">
<p>Damien, Paul, Jon Wakefield, and Stephen Walker. 1999. “Gibbs sampling for Bayesian non-conjugate and hierarchical models by using auxiliary variables.” <em>Journal of the Royal Statistical Society. Series B: Statistical Methodology</em> 61 (2): 331–44. <a href="https://doi.org/10.1111/1467-9868.00179">https://doi.org/10.1111/1467-9868.00179</a>.</p>
</div>
<div id="ref-Polson2014">
<p>Polson, Nicholas G., James G. Scott, and Jesse Windle. 2014. “The Bayesian bridge.” <em>Journal of the Royal Statistical Society. Series B: Statistical Methodology</em> 76 (4): 713–33. <a href="https://doi.org/10.1111/rssb.12042">https://doi.org/10.1111/rssb.12042</a>.</p>
</div>
</div>
</div>

    </div>

    





    
      






  







<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  
  <img class="portrait mr-3" src="/author/admin/avatar_hu52a603635ecebd45650b162dadabb4e5_12861_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
  

  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="/authors/admin">Jiaming Shen</a></h5>
    <h6 class="card-subtitle">PhD candidate in statistics</h6>
    <p class="card-text" itemprop="description">My research interests include Longitudinal data anlaysis, parallel computing, MCMC methods.</p>
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="/#contact" >
          <i class="fas fa-envelope"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://twitter.com/User" target="_blank" rel="noopener">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
      
      
      
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://scholar.google.co.uk/" target="_blank" rel="noopener">
          <i class="ai ai-google-scholar"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/kmsmgsh" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>



      
      
    

    

    
<section id="comments">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "jia-ming-org" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



  </div>
</article>

<div class="container">
  <footer class="site-footer">
  
  <p class="powered-by">
    <a href="/privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//jia-ming-org.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.d7381f2d79e6271d4da28f474f49096c.js"></script>

  </body>
</html>

